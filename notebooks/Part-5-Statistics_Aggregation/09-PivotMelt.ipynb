{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b7a3a1f-ba79-4472-905e-2a3927e838f9",
   "metadata": {},
   "source": [
    "## Pivoting and melting\n",
    "By the end of this lecture you will be able to:\n",
    "- make a `DataFrame` wide with `pivot`\n",
    "- make a `DataFrame` long with `melt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de74c1e5-f4e0-4ada-a943-ec72db1b6234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce426247-e520-44d1-84ee-3226e323d345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csvFile = \"../data/titanic.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9966a283-05bf-4bd9-a573-1b1594238695",
   "metadata": {},
   "source": [
    "## Pivot\n",
    "We start with a simple example of some data on sales of bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e18362-c479-48ca-9511-d906df4d566c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sales_data = pl.DataFrame({\n",
    "    'date': ['2022-01-01', '2022-01-02', '2022-01-01', '2022-01-02','2022-01-03'],\n",
    "    'region': ['East', 'West', 'East', 'West','West'],\n",
    "    'bike_type': ['Mountain', 'Mountain', 'Road', 'Road','Mountain'],\n",
    "    'sales': [100, 200, 300, 400,500]\n",
    "})\n",
    "sales_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d72bd4-dbc1-45ac-9391-f1bcc2534d15",
   "metadata": {},
   "source": [
    "We want to pivot the data so that we have the sales broken down by product, with a row for each date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c04ccf-5529-47e3-ab73-a8526287b35b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    sales_data\n",
    "    .pivot(\n",
    "        index='date', \n",
    "        columns='bike_type', \n",
    "        values='sales'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17995de8-fa75-443a-aef5-d175fe1a7d19",
   "metadata": {},
   "source": [
    "When we use `pivot` we turn a `DataFrame` from long to wide format. Where there is no corresponding value in the original `DataFrame` Polars inserts a `null` value.\n",
    "\n",
    "We can also create new columns from the data in multiple original columns by passing a list of column names to the `columns` argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302c0afe-9b72-4c0b-a722-2449717862fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    sales_data\n",
    "    .pivot(\n",
    "        index='date', \n",
    "        columns=['region','bike_type'], \n",
    "        values='sales'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c886df-5af2-4d28-ba7e-775f8334e9ae",
   "metadata": {},
   "source": [
    "We need to bear in mind that with multiple columns in `columns` we can no longer do horizontal aggregations across the whole row without double counting.\n",
    "\n",
    "### Pivots and aggregation\n",
    "When there are multiple values in the original `DataFrame` that correspond to a position in the pivoted `DataFrame` then Polars must aggregate them.\n",
    "\n",
    "We tell Polars how to aggregate them using the `aggregate_function` argument. We demonstrate this by pivoting by `region`.\n",
    "\n",
    "In our original `DataFrame` we have two values for each region on 2022-01-01 and 2022-01-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578d576e-3fcd-4321-ae03-5d02c562f086",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sales_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d50c60-d3a4-449d-a7c9-06506c45c3ad",
   "metadata": {},
   "source": [
    "We can alternatively specify one of the following aggregation functions: `sum`, `max`, `min`, `mean`, `median`, `last`, `count`.\n",
    "\n",
    "If an aggregation is required but no aggregation function is specified then Polars will raise an exception.\n",
    "\n",
    "In this case we pivot and take the `mean` where there are multiple values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4404ffc0-a502-48d8-8def-654f043f2d53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    sales_data\n",
    "    .pivot(\n",
    "        index='date', \n",
    "        columns='region', \n",
    "        values='sales',\n",
    "        aggregate_function=\"mean\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754447e3-6f1c-4d5f-9652-4a38afd513f1",
   "metadata": {},
   "source": [
    "The pivoted columns are ordered by the order Polars finds them in the column - so in this case there was an `East` entry before a `West` entry.\n",
    "\n",
    "For example if we reverse the `DataFrame` with `.reverse` we get `West` before `East` in the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15401bbf-1434-4f72-af14-a2274f1e7fce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    sales_data\n",
    "    .reverse()\n",
    "    .pivot(\n",
    "        index='date', \n",
    "        columns='region', \n",
    "        values='sales',\n",
    "        aggregate_function=\"mean\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da02ce91-bc20-455c-a136-5f12392f3e44",
   "metadata": {},
   "source": [
    "We can ensure the columns are ordered with the `sort_columns` argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b524cc9a-f836-452c-bdc2-0001b09410e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    sales_data\n",
    "    .reverse()\n",
    "    .pivot(\n",
    "        index='date', \n",
    "        columns='region', \n",
    "        values='sales',\n",
    "        aggregate_function=\"mean\",\n",
    "        sort_columns=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9d3330-7594-4360-8cca-e89e9e0e3050",
   "metadata": {},
   "source": [
    "One final point on aggregation: the `pivot` function is quite similar to a `groupby`. In fact in the internals `pivot` uses the parallel `groupby` on the column(s) in the `index` argument and the columns in `columns` before reshaping the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caea8528-0fac-4fb7-9bec-86c72111e713",
   "metadata": {},
   "source": [
    "### Pivot in lazy mode?\n",
    "In lazy mode Polars must know the schema (column names and dtypes) at each stage of a query plan. However, after a `pivot` the column names cannot be known in advance as they are dependant on the data. As such a `pivot` is not - and will not - be available in lazy mode.  \n",
    "\n",
    "If you have a lazy query but want to do a `pivot` then you can either:\n",
    "- `collect` your query, do the `pivot` and then call `lazy` to resume in lazy mode\n",
    "- try to use `groupby` instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e975867e-8fba-44c4-b70c-be8703efcc18",
   "metadata": {},
   "source": [
    "## Melting from wide to long\n",
    "To convert a `DataFrame` from wide to long we use the `melt` method. This is a common task when transforming data for visualisation libraries as we see in the exercises.\n",
    "\n",
    "We begin this example with a wide `DataFrame` we get from calling `pivot` on `sales_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d215d89c-ebeb-49c9-a50c-da8e304e694d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sales_pv = (\n",
    "    sales_data\n",
    "    .pivot(\n",
    "        index='date', \n",
    "        columns='bike_type', \n",
    "        values='sales',\n",
    "        aggregate_function=\"mean\"\n",
    "    )\n",
    ")\n",
    "sales_pv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7858dca9-5139-4d1c-aa9e-8dc0fdf6d74a",
   "metadata": {},
   "source": [
    "We melt the `DataFrame` by specifying:\n",
    "- which metadata column(s) will identify the data on each row in `id_vars`\n",
    "- which columns will provide the values in `value_vars`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce68f4-253e-4ae0-bee0-fe5fb979d89d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    sales_pv\n",
    "    .melt(\n",
    "        id_vars=\"date\",\n",
    "        value_vars=[\"Mountain\",\"Road\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eacf4ca-9f7e-4982-b7f3-dcc933374ffc",
   "metadata": {},
   "source": [
    "The column names in `value_vars` become the data in the `variable` column.\n",
    "\n",
    "If we want to use all columns not specified in the `id_vars` as `value_vars` we can just omit the `value_vars` argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89255bdf-ffd0-4abd-99ae-fddfbb45e502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    sales_pv\n",
    "    .melt(\n",
    "        id_vars=\"date\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a7adfc-afd4-4db4-bfaf-7c11fca77de6",
   "metadata": {},
   "source": [
    "We can optionally specify different names for the `variable` and `value` column with the `variable_name` and `value_name`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ba6472-6ecc-4a83-affc-ba7a7107e44b",
   "metadata": {},
   "source": [
    "### Melt in lazy mode?\n",
    "We can use `melt` in lazy mode as the new column names (`variable` and `value`) along with their dtypes are known in advance.\n",
    "\n",
    "### Stacking and unstacking?\n",
    "In Pandas there are also methods called `stack` and `unstack`. These work like `melt` and `pivot` except that they convert to/from the index of a Pandas `DataFrame` instead of columns. As Polars doesn't have an index we only need `melt` and `pivot`.\n",
    "\n",
    "\n",
    "## Exercises\n",
    "In the exercises you will develop your understanding of:\n",
    "- converting a `DataFrame` to wide format with `pivot`\n",
    "- converting a `DataFrame` to long format for visualisation with `melt`\n",
    "\n",
    "### Exercise 1\n",
    "For this exercise we use a dataset of bike sales in different countries.\n",
    "\n",
    "We derive a `year` column from the `date` - see the lecture on Extracting datetime components in the Time Series section for more on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85163302-2db9-4ba0-9256-309ed2bb148a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sales_df = (\n",
    "    pl.read_parquet(\"../data/bike_sales.parquet\")\n",
    "    .with_columns(\n",
    "        pl.col(\"date\").dt.year().alias(\"year\")\n",
    "    )\n",
    ")\n",
    "sales_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9333453-b1ec-4aee-aaa2-2912e7058b63",
   "metadata": {},
   "source": [
    "Pivot the data to have a year on each row and a column for each `sub category`. Aggregate by getting the sum of the `order quantity`. Ensure the years are in ascending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfc46bc-dc88-4c32-8e92-fbe703cbec24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    sales_df\n",
    "    <blank>\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7f8e84-8691-404e-a08c-11bb31e730e5",
   "metadata": {},
   "source": [
    "We want to visualise this data as a time series with Plotly so melt the pivoted `DataFrame` and assign it to `annual_sales_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4444dafd-3998-48e8-8112-7f2ff7c4bfbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annual_sales_df = (\n",
    "    sales_df\n",
    "    <blank>\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad82e2b-e5de-4c0a-a15c-10cc554d3055",
   "metadata": {},
   "source": [
    "We can now plot the output using `px.line` in Plotly (feel free to do this with your preferred visualisation library). If you haven't come across Plotly before see the lecture in the Visualisation section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e7f360-b9d3-4cf4-b9b2-5ff32a788dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "px.line(\n",
    "    <blank>\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ce6c24-7218-40ca-8355-d6a1b5d3cddb",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "In this exercise we want to identify which words are present in a set of texts. This is a common task in natual language processing often carried out using the CountVectorizer in Scikit-learn.\n",
    "\n",
    "We begin by defining our `fake_news_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabb6837-a1b9-4a5b-98a1-af8777a285bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news_df = pl.DataFrame({\n",
    "    'publication': ['The Daily Deception', 'Faux News Network', 'The Fabricator', 'The Misleader', \n",
    "                     'The Hoax Herald', ],\n",
    "    'date': ['2022-01-01', '2022-01-03', '2022-01-04', '2022-01-05', '2022-01-06', \n",
    "             ],\n",
    "    'title': ['Scientists Discover New Species of Flying Elephant', \n",
    "              'Aliens Land on Earth and Offer to Solve All Our Problems', \n",
    "              'Study Shows That Eating Pizza Every Day Leads to Longer Life', \n",
    "              'New Study Finds That Smoking is Good for You', \n",
    "              \"World's Largest Iceberg Discovered in Florida\"],\n",
    "    'text': ['In a groundbreaking discovery, scientists have found a new species of elephant that can fly. The flying elephants, which were found in the Amazon rainforest, have wings that span over 50 feet and can reach speeds of up to 100 miles per hour. This is a game-changing discovery that could revolutionize the field of zoology.',\n",
    "             'In a historic moment for humanity, aliens have landed on Earth and offered to solve all our problems. The extraterrestrial visitors, who arrived in a giant spaceship that landed in Central Park, have advanced technology that can cure disease, end hunger, and reverse climate change. The world is waiting to see how this incredible offer will play out.',\n",
    "             'A new study has found that eating pizza every day can lead to a longer life. The study, which was conducted by a team of Italian researchers, looked at the eating habits of over 10,000 people and found that those who ate pizza regularly lived on average two years longer than those who didn\\'t. The study has been hailed as a breakthrough in the field of nutrition.',\n",
    "             'In a surprising twist, a new study has found that smoking is actually good for you. The study, which was conducted by a team of British researchers, looked at the health outcomes of over 100,000 people and found that those who smoked regularly had lower rates of heart disease and cancer than those who didn\\'t. The findings have sparked controversy among health experts.',\n",
    "             'In a bizarre turn of events, the world\\'s largest iceberg has been discovered in Florida. The iceberg, which is over 100 miles long and 50 miles wide, was found off the coast of Miami by a group of tourists on a whale-watching tour. Scientists are baffled by the discovery and are scrambling to figure out how an iceberg of this size could have']\n",
    "})\n",
    "fake_news_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0c479c-b464-4d96-ba6c-daad853d66e3",
   "metadata": {},
   "source": [
    "Begin by:\n",
    "- converting the text to lowercase and splitting the text by whitespace\n",
    "- adding a new column called `placeholder` with 1 as a placeholder value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756614ce-234c-4a27-b3be-82a91fe8a0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    fake_news_data\n",
    "    .with_columns(\n",
    "        <blank>\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248b86af-b49e-4971-bb61-403ce27a2681",
   "metadata": {},
   "source": [
    "Explode the lists in the `text` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9a94d7-ee9f-46ea-ac86-c49629f80461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fa60e49-81ae-42a2-b05d-ed0d4001dd84",
   "metadata": {},
   "source": [
    "Pivot the output so that the article metadata is preserved on each row and the remainder of the columns indicate if the column name is present in the text of that article. Ensure the column names are sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75371493-3cf2-4bcb-9633-0f94c4e693e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b69ddb16-6e04-4855-b8b2-9406c517b9e3",
   "metadata": {},
   "source": [
    "Replace the `null` values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb3a50-8a22-4946-9b82-f5e26d5d5870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f9dc4fd-b03a-47f9-8a4f-fef6b6b343f1",
   "metadata": {},
   "source": [
    "## Solutions\n",
    "\n",
    "### Solution to exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44199f4-022a-47b7-a564-82b62bbd16c2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sales_df = (\n",
    "    pl.read_parquet(\"../data/bike_sales.parquet\")\n",
    "    .with_columns(\n",
    "        pl.col(\"date\").dt.year().alias(\"year\")\n",
    "    )\n",
    ")\n",
    "sales_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f1d610-001e-4ce4-9415-ea4878c1d648",
   "metadata": {},
   "source": [
    "Pivot the data to have a year on each row and a column for each `sub category` of bike. Aggregate by getting the sum of the `order quantity`. Ensure the years are in ascending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb938dae-6497-49f6-83b1-96face7e1d98",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    sales_df\n",
    "    .pivot(\n",
    "        index=\"year\",\n",
    "        columns=\"sub category\",\n",
    "        values=\"order quantity\",\n",
    "        aggregate_function=\"sum\",\n",
    "    )\n",
    "    .sort(\"year\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d351c68-b48d-486c-86b9-0870742ca591",
   "metadata": {},
   "source": [
    "We want to visualise this data as a time series with Plotly so melt the pivoted `DataFrame` and assign it to `annual_sales_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399e6fe1-9f06-4282-af12-48f88dc0f058",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "annual_sales_df = (\n",
    "    sales_df\n",
    "    .pivot(\n",
    "        index=\"year\",\n",
    "        columns=\"sub category\",\n",
    "        values=\"order quantity\",\n",
    "        aggregate_function=\"sum\"\n",
    "    )\n",
    "    .sort(\"year\")\n",
    "    .melt(\n",
    "        id_vars=\"year\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb43b60b-4f06-473b-9dad-6dbfd7eb0983",
   "metadata": {},
   "source": [
    "Plot the output using `px.line`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6cea85-9e3f-465f-bcdd-4ffad0718206",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "px.line(\n",
    "    x=annual_sales_df[\"year\"],\n",
    "    y=annual_sales_df[\"value\"],\n",
    "    color=annual_sales_df[\"variable\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fc9f4b-09d5-48f5-902a-7d52cd23ce29",
   "metadata": {},
   "source": [
    "### Solution to exercise 2\n",
    "In this exercise we want to identify which words are present in a set of texts. This is a common task in natual language processing often carried out using the CountVectorizer in Scikit-learn.\n",
    "\n",
    "We begin by defining our `fake_news_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b39625-32b5-49e0-bdea-e4744953e528",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_news_df = pl.DataFrame({\n",
    "    'publication': ['The Daily Deception', 'Faux News Network', 'The Fabricator', 'The Misleader', \n",
    "                     'The Hoax Herald', ],\n",
    "    'date': ['2022-01-01', '2022-01-03', '2022-01-04', '2022-01-05', '2022-01-06', \n",
    "             ],\n",
    "    'title': ['Scientists Discover New Species of Flying Elephant', \n",
    "              'Aliens Land on Earth and Offer to Solve All Our Problems', \n",
    "              'Study Shows That Eating Pizza Every Day Leads to Longer Life', \n",
    "              'New Study Finds That Smoking is Good for You', \n",
    "              \"World's Largest Iceberg Discovered in Florida\"],\n",
    "    'text': ['In a groundbreaking discovery, scientists have found a new species of elephant that can fly. The flying elephants, which were found in the Amazon rainforest, have wings that span over 50 feet and can reach speeds of up to 100 miles per hour. This is a game-changing discovery that could revolutionize the field of zoology.',\n",
    "             'In a historic moment for humanity, aliens have landed on Earth and offered to solve all our problems. The extraterrestrial visitors, who arrived in a giant spaceship that landed in Central Park, have advanced technology that can cure disease, end hunger, and reverse climate change. The world is waiting to see how this incredible offer will play out.',\n",
    "             'A new study has found that eating pizza every day can lead to a longer life. The study, which was conducted by a team of Italian researchers, looked at the eating habits of over 10,000 people and found that those who ate pizza regularly lived on average two years longer than those who didn\\'t. The study has been hailed as a breakthrough in the field of nutrition.',\n",
    "             'In a surprising twist, a new study has found that smoking is actually good for you. The study, which was conducted by a team of British researchers, looked at the health outcomes of over 100,000 people and found that those who smoked regularly had lower rates of heart disease and cancer than those who didn\\'t. The findings have sparked controversy among health experts.',\n",
    "             'In a bizarre turn of events, the world\\'s largest iceberg has been discovered in Florida. The iceberg, which is over 100 miles long and 50 miles wide, was found off the coast of Miami by a group of tourists on a whale-watching tour. Scientists are baffled by the discovery and are scrambling to figure out how an iceberg of this size could have']\n",
    "})\n",
    "fake_news_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a467f52-7e6e-4235-aecf-172e5512985f",
   "metadata": {},
   "source": [
    "Begin by:\n",
    "- converting the text to lowercase and splitting the text by whitespace\n",
    "- adding a new column called `placeholder` with 1 as a placeholder value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aaa8af-cbaf-4e5f-b0da-9d5830dc072f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    fake_news_df\n",
    "    .with_columns(\n",
    "        pl.col(\"text\").str.to_lowercase().str.split(\" \"),\n",
    "        pl.lit(1).alias(\"placeholder\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4a7bf1-eba9-4d4c-8d11-12fe7bfbc4d6",
   "metadata": {},
   "source": [
    "Explode the lists in the `text` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef77599-8ea3-4d81-a5fa-21a10dd37a60",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    fake_news_df\n",
    "    .with_columns(\n",
    "        pl.col(\"text\").str.to_lowercase().str.split(\" \"),\n",
    "        pl.lit(1).alias(\"placeholder\")\n",
    "    )\n",
    "    .explode(\"text\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a87d41-bf18-4349-a7e5-9a725b2a1b44",
   "metadata": {},
   "source": [
    "Pivot the output so that the article metadata is preserved on each row and the remainder of the columns indicate if the column name is present in the text of that article. Ensure the column names are sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c3a325-079c-4223-8c70-19523164f8b1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    fake_news_df\n",
    "    .with_columns(\n",
    "        pl.col(\"text\").str.to_lowercase().str.split(\" \"),\n",
    "        pl.lit(1).alias(\"placeholder\")\n",
    "    )\n",
    "    .explode(\"text\")\n",
    "    .pivot(\n",
    "        index=[\"publication\",\"date\",\"title\"],\n",
    "        columns=\"text\",\n",
    "        values=\"placeholder\",\n",
    "        sort_columns=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a13b7-dc71-4c28-8d94-6590a401f5e7",
   "metadata": {},
   "source": [
    "Replace the `null` values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b1fe78-db1b-481e-a95f-97e76be555c7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    fake_news_df\n",
    "    .with_columns(\n",
    "        pl.col(\"text\").str.to_lowercase().str.split(\" \"),\n",
    "        pl.lit(1).alias(\"placeholder\")\n",
    "    )\n",
    "    .explode(\"text\")\n",
    "    .pivot(\n",
    "        index=[\"publication\",\"date\",\"title\"],\n",
    "        columns=\"text\",\n",
    "        values=\"placeholder\",\n",
    "        sort_columns=True\n",
    "    )\n",
    "    .fill_null(value=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c5e80c-1c27-4993-a74d-6e4eb8a2810e",
   "metadata": {},
   "source": [
    "If we wanted to split strings with a slightly more sophisticated pattern we could use the following regex (used by CountVectorizer in scikit-learn) and `str.extract_all`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9067735-26f8-472e-94b5-f4b3a083ea59",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    fake_news_df\n",
    "    .with_columns(\n",
    "        pl.col(\"text\").str.to_lowercase().str.extract_all('(?u)\\\\b\\\\w\\\\w+\\\\b'),\n",
    "        pl.lit(1).alias(\"placeholder\")\n",
    "    )\n",
    "    .explode(\"text\")\n",
    "    .pivot(\n",
    "        index=[\"publication\",\"date\",\"title\"],\n",
    "        columns=\"text\",\n",
    "        values=\"placeholder\",\n",
    "        sort_columns=True\n",
    "    )\n",
    "    .fill_null(value=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b9cc5e-d40f-46cc-87cd-d5add81b8d62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
